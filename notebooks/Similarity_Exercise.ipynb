{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5632797-0363-42d8-a43c-2f982988d942",
   "metadata": {},
   "source": [
    "## Similarity Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25a562e-838d-4bed-ae52-ec12552b2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7165c2-90ea-4381-9d3d-edf5c2e1a784",
   "metadata": {},
   "source": [
    "In this exercise, you've been provided the title and abstract of 500 recent machine learning research papers posted on arXiv.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7a796d-eaef-4e97-b787-b4bf5811c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv('../data/arxiv_papers.csv')\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e6836f-5f36-4b60-b21b-b9cbf7e5ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "print(f'Title: {articles.loc[i,\"title\"]}\\n')\n",
    "print(f'Text: {articles.loc[i,\"abstract\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee63919-08d4-400b-bb35-3e9f1b70088a",
   "metadata": {},
   "source": [
    "Let's try out a variety of ways of vectorizing and searching for semantically-similar papers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32294485-637d-4b77-9a9d-2badcdfeb6dd",
   "metadata": {},
   "source": [
    "### Method 1: Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b788ee0-3070-4704-be92-8c442ff4c6d9",
   "metadata": {},
   "source": [
    "Fit a CountVectorizer to the abstracts of the articles with all of the defaults.  Then vectorize the dataset using the fit vectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4cc272-474c-4b48-9e77-5a80cb13534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ee08b-50fa-468c-9655-47b110fa855b",
   "metadata": {},
   "source": [
    "**Question:** How many dimensions do the embeddings have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03208e89-aa86-4daa-bbd8-5952cfe2df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eecfe606-937c-409e-823a-745fe380d407",
   "metadata": {},
   "source": [
    "Now, let's use the embeddings to look for similar articles to a search query.\n",
    "\n",
    "Apply the vectorizer you fit earlier to this query string to get an embedding. \n",
    "\n",
    "**Hint:** You can't pass a string to a vectorizer, but you can pass a list containing a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38271b-eb14-4619-8f00-604bcf9bbdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"vector databases for retrieval augmented generation\"\n",
    "\n",
    "# Your code to transform the search query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f2c931-5dcd-49b7-aa8f-b5bdab82a541",
   "metadata": {},
   "source": [
    "Now, we need to find the similarity between our query embedding and each vectorized article.\n",
    "\n",
    "For this, you can use the [cosine similarity function from scikit-learn.](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html)\n",
    "\n",
    "Calculate the similarity between the query embedding and each article embedding and save the result to a variable named `similarity_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f558bfc-426f-4940-bebd-ce48398e48f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef6eddc-b0a1-4fd0-8381-797313e2bcaa",
   "metadata": {},
   "source": [
    "Now, we need to find the most similar results. To help with this, we can use the [argsort function from numpy](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html), which will give the indices sorted by value. \n",
    "\n",
    "Use the argsort function to find the indices of the 5 most similar articles. Inspect their titles and abstracts. **Warning:** argsort sorts from smallest to largest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3dffd0-5992-4879-a207-08dcc74afca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb94c418-8156-4e76-b41b-26276400a92a",
   "metadata": {},
   "source": [
    "Try using a tfidf vectorizer. How do the results compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5612d4-29a4-4f08-bbeb-efb4ed1f090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed45785-5b64-4234-935a-2bb6e3636d5c",
   "metadata": {},
   "source": [
    "### Method 2: Using a Pretrained Embedding Model\n",
    "\n",
    "Now, let's compare how we do using the [all-MiniLM-L6-v2 embedding model](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2).\n",
    "\n",
    "This will create a 384-dimensional dense embedding of each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b104a-2599-4f02-8bd0-147205f3ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b82b2-a0a3-44be-b89b-097d72a53521",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "embeddings = embedder.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf339d4b-23e6-4034-84bf-7198135f758a",
   "metadata": {},
   "source": [
    "Use this new embedder to vectorize the abstracts and then find the most similar to the query. How do the results compare to the other methods?\n",
    "\n",
    "**Warning:** Creating embeddings for all of the articles may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb666a0-11b3-42fb-b4d0-2e9b5d83dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8dec64-2aa7-40af-adfd-230c19671593",
   "metadata": {},
   "source": [
    "### FAISS\n",
    "\n",
    "The [Faiss library](https://faiss.ai/index.html) is a library for efficient similarity search and clustering of dense vectors. It can be used to automate the process of finding the most similar abstracts.\n",
    "\n",
    "If we want to use cosine similarity, we need to use the Inner Product. We also need to normalize our vectors so that they all have length 1.\n",
    "\n",
    "Use the [normalize function](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html) to normalize both the abstract vectors and the query vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5225fb-e429-4337-92f4-9cdb2468ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393bb61e-471a-4660-99d7-e3e513d34098",
   "metadata": {},
   "source": [
    "Now, create an [IndexFlatIP object](https://github.com/facebookresearch/faiss/wiki/Faiss-indexes#summary-of-methods) that has dimensions equal to the dimensionality of your vectors. Then add your normalized abstract vectors.\n",
    "\n",
    "Hint: You can mimic the example [here](https://github.com/facebookresearch/faiss/wiki/Getting-started#building-an-index-and-adding-the-vectors-to-it), but substitute in the IndexFlatIP class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f7cc7f-8889-4b0c-8bd5-54c760ab4dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e3f95-6f37-4918-800a-094314b9554a",
   "metadata": {},
   "source": [
    "Finally, use the [search function](https://github.com/facebookresearch/faiss/wiki/Getting-started#searching) on your index object to find the 5 most similar articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f884c016-444b-4714-85fc-07a8cdaf2247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
